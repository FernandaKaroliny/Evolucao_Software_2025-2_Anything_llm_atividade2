{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlUjZGyLPaXC"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate requests bitsandbytes\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "import json\n",
        "from datetime import datetime\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "REPO = \"Mintplex-Labs/anything-llm\"\n",
        "MODEL_NAME = \"microsoft/Phi-3.5-mini-instruct\"\n"
      ],
      "metadata": {
        "id": "dumZR-SNYmtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coletar_dados():\n",
        "    releases = requests.get(\n",
        "        f\"https://api.github.com/repos/{REPO}/releases?per_page=10\"\n",
        "    ).json()\n",
        "\n",
        "    commits = requests.get(\n",
        "        f\"https://api.github.com/repos/{REPO}/commits?per_page=30\"\n",
        "    ).json()\n",
        "\n",
        "    return releases, commits\n",
        "\n",
        "\n",
        "def salvar_json(nome_arquivo, conteudo):\n",
        "    with open(nome_arquivo, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(conteudo, f, indent=2, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "O52uNP3FYmpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "releases, commits = coletar_dados()\n",
        "\n",
        "salvar_json(\n",
        "    \"dados_anythingllm.json\",\n",
        "    {\n",
        "        \"repositorio\": REPO,\n",
        "        \"coletado_em\": datetime.now().isoformat(),\n",
        "        \"releases\": releases,\n",
        "        \"commits\": commits\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "hTzfbXFDYmkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "release_info = []\n",
        "for r in releases:\n",
        "    tag = r.get(\"tag_name\", \"N/A\")\n",
        "    date = r.get(\"published_at\", \"N/A\")\n",
        "    release_info.append(f\"{tag} - {date}\")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Você é um especialista em Engenharia de Software.\n",
        "\n",
        "Com base APENAS nos dados abaixo, identifique a ESTRATÉGIA DE RELEASES\n",
        "do projeto AnythingLLM.\n",
        "\n",
        "DADOS DE RELEASES (tag - data):\n",
        "{chr(10).join(release_info)}\n",
        "\n",
        "TOTAL DE RELEASES ANALISADAS: {len(releases)}\n",
        "TOTAL DE COMMITS RECENTES ANALISADOS: {len(commits)}\n",
        "\n",
        "CLASSIFIQUE A ESTRATÉGIA COMO UMA DAS SEGUINTES:\n",
        "- Rapid Releases\n",
        "- Release Train\n",
        "- LTS + Current\n",
        "- Ad hoc / Irregular\n",
        "\n",
        "RESPONDA NO FORMATO:\n",
        "1. Estratégia identificada:\n",
        "2. Frequência observada:\n",
        "3. Uso de versionamento semântico (Sim/Não):\n",
        "4. Justificativa baseada nos dados:\n",
        "\"\"\"\n",
        "\n",
        "salvar_json(\n",
        "    \"prompt_anythingllm.json\",\n",
        "    {\n",
        "        \"modelo\": MODEL_NAME,\n",
        "        \"prompt\": prompt\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "zA7K4v6jX-EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config,\n",
        "    trust_remote_code=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "fLz0abYyYj4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    prompt,\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    max_length=2048\n",
        ")\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=400,\n",
        "        temperature=0.1,\n",
        "        do_sample=False\n",
        "    )\n",
        "\n",
        "resposta = tokenizer.decode(\n",
        "    output[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(\"===== RESULTADO FINAL =====\\n\")\n",
        "print(resposta)\n"
      ],
      "metadata": {
        "id": "nujttJazZQdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salvar_json(\n",
        "    \"resultado_analise_anythingllm.json\",\n",
        "    {\n",
        "        \"repositorio\": REPO,\n",
        "        \"modelo\": MODEL_NAME,\n",
        "        \"data_analise\": datetime.now().isoformat(),\n",
        "        \"resultado\": resposta\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"\\nArquivos gerados:\")\n",
        "print(\"- dados_anythingllm.json\")\n",
        "print(\"- prompt_anythingllm.json\")\n",
        "print(\"- resultado_analise_anythingllm.json\")\n"
      ],
      "metadata": {
        "id": "47H6OKLJZSX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wSF2BrAIX6BT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}